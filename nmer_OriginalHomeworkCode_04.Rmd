---
title: "nmer_OriginalHomeworkCode_04"
author: "Nicole Merullo"
date: "2023-10-22"
output:
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
    toc: true
---

# Homework 4 What's Your Malfunction?
```{r formuoli, echo=FALSE, fig.align='center', out.width='25%'}
knitr::include_graphics('https://media.giphy.com/media/3oz8xUEbvqSrbGuQla/giphy.gif') 
```

## Challenges:
1. Telling the formula to do a one sample z test with p2 and n2 as null. I was getting a warning that I needed to use is.null but I thought I still needed to put that after the == for each object. After searching around, I realized it was kind of its own function. <br>
2. Could not figure out how to get the conf.level to vary in the CI part of the formula. Found a way to do this in Module 7. I double checked this worked and what I had for my formula using the Module 10 Challenge 4 example data for a one sample proportion z test. <br>
3. Figuring out the CI for the two sample proportation test was tricky. I used a test from Challenge 5 in Module 10 and broke it down by each component to make sure the formula was working at each part: z statistic, p value, etc. My CI were not quite working out because I tried replacing instances of p1 with p2-p1 from the one sample. Instead, I defined SE for clarity and used pstar. This got me the right values that the Module 10 Challenge 5 answers has. <br>
4. I could not figure out the legends on the plots in question 2. I read a lot of the documentation and used the tidyverse textbook and eventually moved my parentheses to include the color argument inside the aes() mapping and then instead of using actual colors inside I used strings and then referenced those strings in scale_color_manual(values = c("fit" = "black","CI" = "blue","PI" = "red")) where I defined the colors.
5. Sometimes the point estimate worked and other times it did not for the last part of question 2. When I plugged in the brain size into predict, copying right from module 12 challenge 4 where we predicted prediction intervals for a single vector, sometimes it would give me a single point estimate and associate CI and other times it would give me 26! I can't find a difference between the two instances but I am sure I am missing it. Additionally, I was not sure if I should use beta1 * 800 + beta0 or predict() set to a single vector, so I did both but these got different point estimates.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(curl)
library(ggplot2)
```

## Z.prop.test

-Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test(). <br>
-When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test(). <br>
-The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.<br>
-The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message. <br>
-The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds. <br>

```{r formula-1}
Z.prop.test <- function(p0, p1, n1, p2 = NULL, n2 = NULL, alternative = "two.sided", conf.level = 0.95) {}
```


```{r formula-2}
Z.prop.test <- function(p0, p1, n1, p2 = NULL, n2 = NULL, alternative = "two.sided", conf.level = 0.95) 
{
 if (is.null(p2) | is.null(n2)) {
   z <- (p1 - p0)/sqrt(p0*(1 - p0) / n1) #one sample z test
   if (alternative == "greater") {p <- pnorm(z, lower.tail = FALSE)}
   if (alternative == "less") {p <- pnorm(z, lower.tail = TRUE)}
   if (alternative == "two.sided") {
            if (z > 0)
                {
                p <- 2 * pnorm(z, lower.tail = FALSE)
                }
            if (z < 0)
                {
                p <- 2 * pnorm(z, lower.tail = TRUE)
            }} #taking the p value with respect to the left tail or the right tail
  upper <- p1 + qnorm(1 - (1 - conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
  lower <- p1 + qnorm((1 - conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
  ci <- c(lower, upper) }
  return(c(z,p, ci))
}
```

```{r test}
Z.prop.test(p0 = 0.8, p1 = 0.6, n1 = 30, alternative = "less")
```

```{r formula-3}
Z.prop.test <- function(p0, p1, n1, p2 = NULL, n2 = NULL, alternative = "two.sided", conf.level = 0.95) 
{
 if (is.null(p2) | is.null(n2)) {
   z <- (p1 - p0)/sqrt(p0*(1 - p0) / n1) #one sample z test
   if (alternative == "greater") {p <- pnorm(z, lower.tail = FALSE)}
   if (alternative == "less") {p <- pnorm(z, lower.tail = TRUE)}
   if (alternative == "two.sided") {
            if (z > 0)
                {
                p <- 2 * pnorm(z, lower.tail = FALSE)
                }
            if (z < 0)
                {
                p <- 2 * pnorm(z, lower.tail = TRUE)
            }} #Adapted from Module 11
  upper <- p1 + qnorm(1 - (1 - conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
  lower <- p1 + qnorm((1 - conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
  ci <- c(lower, upper) }
 else {
   pstar <- (p1+p2)/2 #simplification of the pstar equation from module 10
   z <- (p2 - p1 - p0)/sqrt((pstar * (1 - pstar)) * (1/n1 + 1/n2))
    if (alternative == "greater") {p <- pnorm(z, lower.tail = FALSE)}
    if (alternative == "less") {p <- pnorm(z, lower.tail = TRUE)}
    if (alternative == "two.sided") {p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)} #adapted from module 10
   se <- sqrt(pstar * (1-pstar) * (1/n1 + 1/n2))
   upper <- (p2-p1) + qnorm(1 - (1 - conf.level)/2) * se
   lower <- (p2-p1) + qnorm((1 - conf.level)/2) * se
   ci <- c(lower, upper)
 } 
  return(c(z,p, ci))
}
```

```{r test-2}
v1 <- c(1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,
    1, 0)
n1 <- length(v1)
v2 <- c(1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,
    0, 1, 1, 0, 1, 1, 1)
n2 = length(v2)
Z.prop.test(p0=0, p1=mean(v1), p2=mean(v2), n1=n1, n2=n2)
```


```{r formula-4}
Z.prop.test <- function(p0, p1, n1, p2 = NULL, n2 = NULL, alternative = "two.sided", conf.level = 0.95) 
{
 if (is.null(p2) | is.null(n2)) {
   if ( (n1 * p1) < 5 | (n1 * (1 - p1)) < 5 ) 
  {print("Warning: This test violates the expectation based on the approximation of the normal")}
   z <- (p1 - p0)/sqrt(p0*(1 - p0) / n1) #one sample z test
   if (alternative == "greater") {p <- pnorm(z, lower.tail = FALSE)}
   if (alternative == "less") {p <- pnorm(z, lower.tail = TRUE)}
   if (alternative == "two.sided") {
            if (z > 0)
                {
                p <- 2 * pnorm(z, lower.tail = FALSE)
                }
            if (z < 0)
                {
                p <- 2 * pnorm(z, lower.tail = TRUE)
            }} #Adapted from Module 11
  upper <- p1 + qnorm(1 - (1 - conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
  lower <- p1 + qnorm((1 - conf.level)/2) * sqrt(p1 * (1 - p1)/n1)
  ci <- c(lower, upper) }
 else {
   if ((n2 * p2) < 5 | (n2 * (1 - p2)) < 5) 
  {print("Warning: This test violates the expectation based on the approximation of the normal")}
   pstar <- (p1+p2)/2 #simplification of the pstar equation from module 10
   z <- (p2 - p1 - p0)/sqrt((pstar * (1 - pstar)) * (1/n1 + 1/n2))
    if (alternative == "greater") {p <- pnorm(z, lower.tail = FALSE)}
    if (alternative == "less") {p <- pnorm(z, lower.tail = TRUE)}
    if (alternative == "two.sided") {p <- 1 - pnorm(z, lower.tail = TRUE) + pnorm(z, lower.tail = FALSE)} #adapted from module 10
   se <- sqrt(pstar * (1-pstar) * (1/n1 + 1/n2))
   upper <- (p2-p1) + qnorm(1 - (1 - conf.level)/2) * se
   lower <- (p2-p1) + qnorm((1 - conf.level)/2) * se
   ci <- c(lower, upper)
 } 
  return(c(z,p,ci))
  }
```

```{r test-3}
Z.prop.test(p0 = 0.8, p1 = 0.6, n1 = 5, alternative = "less")
Z.prop.test(p0=0, p1=0.66, n1=3, p2=0.75, n2=4, alternative = "greater")
```
## Kamilar and Cooper Data
The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):


Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

```{r Data}
file <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv")
d <- read.csv(file, header= TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```

Fitting the models

```{r lm}
d <- na.omit(d)
l <- d$MaxLongevity_m
b <- d$Brain_Size_Species_Mean
LOGl <-log(d$MaxLongevity_m)
LOGb <- log(d$Brain_Size_Species_Mean)
m <- lm(data = d, l~b)
summary(m)
logm <- lm(data = d, LOGl~LOGb)
summary(logm)
```
 Plotting
 
```{r Scatterplot}
beta1 <- cor(l, b) * (sd(b)/sd(l))
beta1
beta0 <- mean(l) - beta1 * mean(b)
beta0
log.beta1 <- cor(LOGb, LOGl) * (sd(LOGb)/sd(LOGl))
log.beta1
log.beta0 <- mean(LOGl) - log.beta1 * mean(LOGb)
log.beta0
par(mfrow = c(2,1))
p1 <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
p1 <- p1 + geom_point()
p1 <- p1 + geom_smooth(method = "lm", formula = y ~ x)
p1 <- p1 + geom_text(x = 400, y = 400, label = "cor(b, l)*(sd(b)/sd(l))= 0.60885", colour = "olivedrab4")
p1
pLog <- ggplot(data = d, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m)))
pLog <- pLog + geom_point()
pLog <- pLog + geom_smooth(method = "lm", formula = y ~ x)
pLog <- pLog + geom_text(x = 3, y = 6.4, label = "cor(LOGb, LOGl)*(sd(LOGb)/sd(LOGl))= 2.004351", colour = "olivedrab4", size = 3)
pLog
```


Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.

As brain size increases by 1, longevity increases by 0.60885 or 2.00435.
Since B1 does not equal zero, we reject the null hypothesis and accept the alternative hypothesis. As brain size increases, longevity increases.

```{r CIforb1}
#non-transformed data
m <- lm(data = d, l ~ b) #fitting the model y~x
ci <- predict(m, newdata = data.frame(Brainsize = d$Brain_Size_Species_Mean), interval = "confidence", level = 0.90)  #predicting the 90% CI at the x values
head(ci)
df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, ci)) #binding the x and y axes with the fit, lower, and upper values from the predict function
head(df) #checking the number of columns
names(df) <- c("x", "y", "CIfit", "CIlwr", "CIupr") #naming the columns
head(df)
g <- ggplot(data = df, aes(x = x, y = y)) #plotting longevity (y) against brain size (x) but this time from the data frame I just made
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit), colour = "black") #fitting the linear regression
g <- g + geom_line(aes(x = x, y = CIlwr), colour = "blue") #fitting the lower CI line
g <- g + geom_line(aes(x = x, y = CIupr), colour = "blue") #fitting the upper CI line
g
# log plot
logm <- lm(LOGl~LOGb) # fitting the model y~x
ci <- predict(logm, newdata = data.frame(BrainSize = LOGb), interval = "confidence", level = 0.90)  #predicting the 90% CI at the x values
head(ci)
logdf <- data.frame(cbind(LOGb, LOGl, ci))
head(logdf)
names(logdf) <- c("x", "y", "CIfit", "CIlwr", "CIupr")
head(logdf)
logg <- ggplot(data = logdf, aes(x = x, y = y))
logg <- logg + geom_point(alpha = 1/2)
logg <- logg + geom_line(aes(x = x, y = CIfit), colour = "black")
logg <- logg + geom_line(aes(x = x, y = CIlwr), colour = "blue")
logg <- logg + geom_line(aes(x = x, y = CIupr), colour = "blue")
logg
```

Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

```{r CIandPI}
#non-transformed data
pi <- predict(m, newdata = data.frame(Brainsize = d$Brain_Size_Species_Mean), interval = "prediction",
    level = 0.90)  # for a vector of values
head(pi)
dfpi <- cbind(df, pi)
names(dfpi) <- c("x", "y", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(dfpi)
g <- ggplot(data = dfpi, aes(x = x, y = y)) #pasted in ggplot code from above but changed data frame it is pulling from
g <- g + geom_point(alpha = 1/2) + 
  geom_line(aes(x = x, y = CIfit, colour = "fit")) +
  geom_line(aes(x = x, y = CIlwr, colour = "CI")) +
  geom_line(aes(x = x, y = CIupr, colour = "CI")) +
  geom_line(aes(x = x, y = PIlwr, colour = "PI")) +
  geom_line(aes(x = x, y = PIupr, colour = "PI")) +
  scale_color_manual(values = c("fit" = "black","CI" = "blue","PI" = "red")) + 
  theme(legend.position = "bottom", legend.title = element_blank())
g
# log plot
pi <- predict(logm, newdata = data.frame(BrainSize = LOGb), interval = "prediction", level = 0.90)
head(pi)
logdfpi <- cbind(logdf, pi)
names(logdfpi) <- c("x", "y", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(logdfpi)
logg <- ggplot(data = logdfpi, aes(x = x, y = y)) +
  geom_point(alpha = 1/2) +
  geom_line(aes(x = x, y = CIfit, colour = "fit")) +
  geom_line(aes(x = x, y = CIlwr, colour = "CI")) +
  geom_line(aes(x = x, y = CIupr, colour = "CI")) +
  geom_line(aes(x = x, y = PIlwr, colour = "PI")) +
  geom_line(aes(x = x, y = PIupr, colour = "PI")) +
  scale_color_manual(values = c("fit" = "black","CI" = "blue","PI" = "red")) + 
  theme(legend.position = "bottom", legend.title = element_blank())
logg
```

Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

I am not sure the non-transformed version is appropriate for predicting longevity at this high of a value. The data are more concentrated at the lower end of the x values, and may be less predictive at the higher end. The log transformed version redistributes the data close more evenly, and log(800) is closer to the end of the x limit as it looks right now. I couldn't get a point estimate for this one using predict() for some reason (please take a look at why this might be!) so it's hard to evaluate if this is more appropriate or now.

```{r 800gm}
longlife.est <- beta1 * 800 + beta0
longlife.est
longlife.pi <- predict(m, newdata = data.frame(b = 800), interval = "prediction",
    level = 0.90)
longlife.pi
log.longlife.est <- log.beta1 * log(800) + log.beta0
log.longlife.est
log.longlife.pi <- predict(m, newdata = data.frame(LOGb = log(800)), interval = "prediction", level = 0.90)
log.longlife.pi
```

Looking at your two models, which do you think is better? Why?

I think the log transformed one is better because the data cloud is more spread out and the tightness in the CI lines are more in the middle (mean)
